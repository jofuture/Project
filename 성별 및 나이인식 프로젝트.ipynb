{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI_02_조미래_CS1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP0Pdd/SKRQMAl8r/pUhBu/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jofuture/project/blob/main/AI_02_%EC%A1%B0%EB%AF%B8%EB%9E%98_CS1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m91QptWrMFQl"
      },
      "source": [
        "import numpy as np                      # 프레임을 Matrix로 연산하는 라이브러리\n",
        "import cv2                              # OpenCV 라이브러리\n",
        "import time                             # 시간측정을 위한 라이브러리\n",
        "from tkinter import *\n",
        "from PIL import Image\n",
        "from PIL import ImageTk\n",
        "from tkinter import filedialog\n",
        "import tkinter.scrolledtext as tkst\n",
        "\n",
        "face_model = './model/res10_300x300_ssd_iter_140000.caffemodel'\n",
        "face_prototxt = './model/deploy.prototxt.txt' # 모델에 대한 메타 정보\n",
        "age_model = './model/age_net.caffemodel'\n",
        "age_prototxt = './model/age_deploy.prototxt'\n",
        "gender_model = './model/gender_net.caffemodel'\n",
        "gender_prototxt = './model/gender_deploy.prototxt'\n",
        "\n",
        "age_list = ['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']\n",
        "gender_list = ['Male','Female']\n",
        "\n",
        "title_name = 'Age and Gender Recognition'\n",
        "min_confidence = 0.5 # 최소 신뢰도\n",
        "recognition_count = 0\n",
        "elapsed_time = 0\n",
        "OUTPUT_SIZE = (300, 300)\n",
        "\n",
        "detector = cv2.dnn.readNetFromCaffe(face_prototxt, face_model)\n",
        "age_detector = cv2.dnn.readNetFromCaffe(age_prototxt, age_model)\n",
        "gender_detector = cv2.dnn.readNetFromCaffe(gender_prototxt, gender_model)\n",
        "\n",
        "    \n",
        "def detectAndDisplay(image): # 이미지 받고\n",
        "    start_time = time.time() # 시간 측정\n",
        "    (h, w) = image.shape[:2] # width , height 가져오기\n",
        "\n",
        "    # 얼굴 탐지 부분\n",
        "    imageBlob = cv2.dnn.blobFromImage(image, 1.0, OUTPUT_SIZE, # 1.0은 스케일 값, blob은 사이즈를 바꿔준다\n",
        "        (104.0, 177.0, 123.0), swapRB=False, crop=False) # min subtract\n",
        "        # min subtraction      # BGR형태로 바꿀건지\n",
        "    detector.setInput(imageBlob) # 얼굴 찾기\n",
        "    detections = detector.forward()\n",
        "\n",
        "    for i in range(0, detections.shape[2]):\n",
        "        # 신뢰도 추측\n",
        "        confidence = detections[0, 0, i, 2]\n",
        "\n",
        "        # 신뢰도를 높여 약한 탐지를 걸러낸다.\n",
        "        # 최소 신뢰 이상\n",
        "        if confidence > min_confidence:\n",
        "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
        "\n",
        "            # 얼굴의 ROI(region of interest - 관심영역) 를 추출한다.\n",
        "            face = image[startY:endY, startX:endX]\n",
        "            (fH, fW) = face.shape[:2]\n",
        "\n",
        "            # 얼굴의 ROI만으로 BLOB 구성하기\n",
        "            face_blob = cv2.dnn.blobFromImage(face, 1.0, (227, 227),\n",
        "                    (78.4263377603, 87.7689143744, 114.895847746),swapRB=False)\n",
        "            \n",
        "\n",
        "            # 나이 예측\n",
        "            # 가장 큰 대응 확률\n",
        "            age_detector.setInput(face_blob)\n",
        "            age_predictions = age_detector.forward()\n",
        "            age_index = age_predictions[0].argmax()\n",
        "            age = age_list[age_index]\n",
        "            age_confidence = age_predictions[0][age_index]\n",
        "            \n",
        "            gender_detector.setInput(face_blob)\n",
        "            gender_predictions = gender_detector.forward()\n",
        "            gender_index = gender_predictions[0].argmax()\n",
        "            gender = gender_list[gender_index]\n",
        "            gender_confidence = gender_predictions[0][gender_index]\n",
        "\n",
        "            text = \"{}: {:.2f}% {}: {:.2f}%\".format(gender, gender_confidence*100, age, age_confidence*100)\n",
        "            y = startY - 10 if startY - 10 > 10 else startY + 10\n",
        "            cv2.rectangle(image, (startX, startY), (endX, endY), # 얼굴 윤곽 그리고\n",
        "                (0, 255, 0), 2)\n",
        "            cv2.putText(image, text, (startX, y), # 텍스트 보여주기\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 2)\n",
        "            print('==============================')\n",
        "            print(\"Gender {} time {:.2f} %\".format(gender, gender_confidence*100))\n",
        "            print(\"Age {} time {:.2f} %\".format(age, age_confidence*100))\n",
        "            print(\"Age     Probability(%)\")\n",
        "            for i in range(len(age_list)):\n",
        "                print(\"{}  {:.2f}%\".format(age_list[i], age_predictions[0][i]*100))\n",
        "                \n",
        "            print(\"Gender  Probability(%)\")\n",
        "            for i in range(len(gender_list)):\n",
        "                print(\"{}  {:.2f} %\".format(gender_list[i], gender_predictions[0][i]*100))\n",
        "                \n",
        "\n",
        "                \n",
        "    frame_time = time.time() - start_time\n",
        "    global elapsed_time\n",
        "    elapsed_time += frame_time\n",
        "    print(\"Frame time {:.3f} seconds\".format(frame_time))\n",
        "    \n",
        "    cv2.imshow(title_name, image)\n",
        "    \n",
        "\n",
        "vs = cv2.VideoCapture(0, cv2.CAP_DSHOW) # 카메라 스트림 연결, 0: 자체 카메라 1: usb카메라,  CAP_DSHOW는 에러방지 \n",
        "time.sleep(1.0)\n",
        "if not vs.isOpened: # 카메라가 안열릴 때\n",
        "    print('### Error opening video ###')\n",
        "    exit(0)\n",
        "while True:\n",
        "    ret, frame = vs.read()\n",
        "    if frame is None:\n",
        "        print('### No more frame ###')\n",
        "        vs.release()\n",
        "        break\n",
        "    detectAndDisplay(frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'): # 화면 끝낼때 \n",
        "        break\n",
        "\n",
        "\n",
        "vs.release() # 메모리 저장 \n",
        "cv2.destroyAllWindows() # 완전 종료 \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
